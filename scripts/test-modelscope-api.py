#!/usr/bin/env python3
"""
é­”æ­APIé›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯•JoyAgentä¸é­”æ­APIçš„é›†æˆæƒ…å†µ
"""

import json
import time
from openai import OpenAI

# é…ç½®ä¿¡æ¯
API_KEY = 
BASE_URL = "https://api-inference.modelscope.cn/v1"

# æµ‹è¯•æ¨¡å‹åˆ—è¡¨
MODELS = [
    "Qwen/Qwen2.5-7B-Instruct",
    "Qwen/Qwen2.5-14B-Instruct", 
    "Qwen/Qwen2.5-Coder-32B-Instruct"
]

def test_model_availability():
    """æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§"""
    print("ğŸ” æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§...")
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    for model in MODELS:
        try:
            print(f"  æµ‹è¯•æ¨¡å‹: {model}")
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": "ä½ å¥½"}],
                max_tokens=10,
                stream=False
            )
            print(f"  âœ… {model} - å¯ç”¨")
            print(f"     å“åº”: {response.choices[0].message.content}")
        except Exception as e:
            print(f"  âŒ {model} - é”™è¯¯: {str(e)}")
        print()

def test_streaming_output():
    """æµ‹è¯•æµå¼è¾“å‡º"""
    print("ğŸŒŠ æµ‹è¯•æµå¼è¾“å‡º...")
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    try:
        print("  ä½¿ç”¨æ¨¡å‹: Qwen/Qwen2.5-7B-Instruct")
        print("  é—®é¢˜: è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½")
        print("  æµå¼å“åº”:")
        print("  " + "-" * 50)
        
        response = client.chat.completions.create(
            model="Qwen/Qwen2.5-7B-Instruct",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´å›ç­”é—®é¢˜ã€‚"
                },
                {
                    "role": "user", 
                    "content": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
                }
            ],
            stream=True,
            max_tokens=200,
            temperature=0.7
        )
        
        full_response = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end='', flush=True)
                full_response += content
        
        print("\n  " + "-" * 50)
        print(f"  âœ… æµå¼è¾“å‡ºæµ‹è¯•æˆåŠŸ")
        print(f"  ğŸ“Š æ€»å­—ç¬¦æ•°: {len(full_response)}")
        
    except Exception as e:
        print(f"  âŒ æµå¼è¾“å‡ºæµ‹è¯•å¤±è´¥: {str(e)}")

def test_code_generation():
    """æµ‹è¯•ä»£ç ç”Ÿæˆèƒ½åŠ›"""
    print("ğŸ’» æµ‹è¯•ä»£ç ç”Ÿæˆèƒ½åŠ›...")
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    try:
        print("  ä½¿ç”¨æ¨¡å‹: Qwen/Qwen2.5-Coder-32B-Instruct")
        print("  ä»»åŠ¡: ç”ŸæˆPythonå¿«é€Ÿæ’åºä»£ç ")
        
        response = client.chat.completions.create(
            model="Qwen/Qwen2.5-Coder-32B-Instruct",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œè¯·ç”Ÿæˆé«˜è´¨é‡çš„ä»£ç ã€‚"
                },
                {
                    "role": "user",
                    "content": "è¯·ç”¨Pythonå®ç°ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ï¼Œè¦æ±‚ä»£ç ç®€æ´ä¸”æœ‰æ³¨é‡Š"
                }
            ],
            stream=False,
            max_tokens=500,
            temperature=0.1
        )
        
        code = response.choices[0].message.content
        print("  ç”Ÿæˆçš„ä»£ç :")
        print("  " + "-" * 50)
        print(code)
        print("  " + "-" * 50)
        print("  âœ… ä»£ç ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
        
    except Exception as e:
        print(f"  âŒ ä»£ç ç”Ÿæˆæµ‹è¯•å¤±è´¥: {str(e)}")

def test_startup_consulting():
    """æµ‹è¯•åˆ›ä¸šå’¨è¯¢åœºæ™¯"""
    print("ğŸš€ æµ‹è¯•åˆ›ä¸šå’¨è¯¢åœºæ™¯...")
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    try:
        print("  ä½¿ç”¨æ¨¡å‹: Qwen/Qwen2.5-14B-Instruct")
        print("  åœºæ™¯: åˆ›ä¸šé¡¹ç›®SWOTåˆ†æ")
        
        response = client.chat.completions.create(
            model="Qwen/Qwen2.5-14B-Instruct",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ›ä¸šé¡¾é—®ï¼Œæ“…é•¿å•†ä¸šåˆ†æå’Œæˆ˜ç•¥è§„åˆ’ã€‚"
                },
                {
                    "role": "user",
                    "content": "æˆ‘æƒ³åšä¸€ä¸ªAIé©±åŠ¨çš„åœ¨çº¿æ•™è‚²å¹³å°ï¼Œè¯·å¸®æˆ‘åšä¸€ä¸ªç®€å•çš„SWOTåˆ†æ"
                }
            ],
            stream=True,
            max_tokens=800,
            temperature=0.7
        )
        
        print("  SWOTåˆ†æç»“æœ:")
        print("  " + "-" * 50)
        
        full_response = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end='', flush=True)
                full_response += content
        
        print("\n  " + "-" * 50)
        print("  âœ… åˆ›ä¸šå’¨è¯¢æµ‹è¯•æˆåŠŸ")
        
    except Exception as e:
        print(f"  âŒ åˆ›ä¸šå’¨è¯¢æµ‹è¯•å¤±è´¥: {str(e)}")

def test_api_limits():
    """æµ‹è¯•APIé™åˆ¶"""
    print("âš¡ æµ‹è¯•APIå“åº”æ—¶é—´...")
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    try:
        start_time = time.time()
        
        response = client.chat.completions.create(
            model="Qwen/Qwen2.5-7B-Instruct",
            messages=[{"role": "user", "content": "1+1ç­‰äºå‡ ï¼Ÿ"}],
            max_tokens=10,
            stream=False
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        print(f"  ğŸ“Š å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        print(f"  ğŸ“ å“åº”å†…å®¹: {response.choices[0].message.content}")
        
        if response_time < 5:
            print("  âœ… å“åº”æ—¶é—´æ­£å¸¸")
        else:
            print("  âš ï¸  å“åº”æ—¶é—´è¾ƒæ…¢")
            
    except Exception as e:
        print(f"  âŒ APIé™åˆ¶æµ‹è¯•å¤±è´¥: {str(e)}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª é­”æ­APIé›†æˆæµ‹è¯•å¼€å§‹")
    print("=" * 60)
    print(f"API Token: {API_KEY}")
    print(f"Base URL: {BASE_URL}")
    print("=" * 60)
    print()
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    test_model_availability()
    print()
    
    test_streaming_output()
    print()
    
    test_code_generation()
    print()
    
    test_startup_consulting()
    print()
    
    test_api_limits()
    print()
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("ğŸ’¡ æç¤º: å¦‚æœæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œè¯´æ˜é­”æ­APIé›†æˆæˆåŠŸ")
    print("ğŸ“Š å»ºè®®: ç›‘æ§æ¯æ—¥APIä½¿ç”¨é‡ï¼Œé¿å…è¶…è¿‡2000æ¬¡é™åˆ¶")

if __name__ == "__main__":
    main()