#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•LLMé›†æˆ
"""

import asyncio
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡ - ä¿®æ­£è·¯å¾„åˆ°é¡¹ç›®æ ¹ç›®å½•
env_root = Path(__file__).parent.parent.parent.parent.parent.parent
print(f"ç¯å¢ƒå˜é‡è·¯å¾„: {env_root}")

# ç¡®ä¿è·¯å¾„æ­£ç¡®
if not (env_root / ".env.local").exists():
    # å¦‚æœè·¯å¾„ä¸å¯¹ï¼Œå°è¯•ä»å½“å‰å·¥ä½œç›®å½•æŸ¥æ‰¾
    env_root = Path.cwd()
    print(f"å›é€€åˆ°å·¥ä½œç›®å½•: {env_root}")

# å…ˆåŠ è½½.envï¼Œå†åŠ è½½.env.localï¼ˆåè€…ä¼šè¦†ç›–å‰è€…ï¼‰
load_dotenv(env_root / ".env")
load_dotenv(env_root / ".env.local", override=True)

# éªŒè¯ç¯å¢ƒå˜é‡æ˜¯å¦åŠ è½½æˆåŠŸ
api_key = os.getenv("MODELSCOPE_ACCESS_TOKEN")
print(f"ç¯å¢ƒå˜é‡åŠ è½½ç»“æœ: {'æˆåŠŸ' if api_key else 'å¤±è´¥'}")

from com.jd.genie.agent.llm.LLMService import llm_service
from com.startup.agents.agent_factory import AgentFactory


async def test_llm_service():
    """æµ‹è¯•LLMæœåŠ¡"""
    print("ğŸ§ª æµ‹è¯•LLMæœåŠ¡...")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("MODELSCOPE_ACCESS_TOKEN")
    print(f"API Key: {api_key[:10]}..." if api_key else "æœªæ‰¾åˆ°API Key")
    
    # æµ‹è¯•ç®€å•è°ƒç”¨
    try:
        response = await llm_service.generate_response(
            prompt="è¯·å›ç­”ï¼š1+1ç­‰äºå¤šå°‘ï¼Ÿ",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹",
            temperature=0.1,
            max_tokens=50
        )
        print(f"LLMå“åº”: {response}")
        return True
    except Exception as e:
        print(f"LLMæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_requirement_analysis_agent():
    """æµ‹è¯•éœ€æ±‚åˆ†ææ™ºèƒ½ä½“"""
    print("\nğŸ¤– æµ‹è¯•éœ€æ±‚åˆ†ææ™ºèƒ½ä½“...")
    
    try:
        agent = AgentFactory.create_agent("requirement_analysis")
        if not agent:
            print("æ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥")
            return False
        
        parameters = {
            "project_description": "å¼€å‘ä¸€ä¸ªAIèŠå¤©æœºå™¨äººåº”ç”¨",
            "analysis_type": "comprehensive"
        }
        
        result = await agent.run("è¯·åˆ†æè¿™ä¸ªAIèŠå¤©æœºå™¨äººé¡¹ç›®", parameters)
        
        if result.get("success"):
            print("âœ… éœ€æ±‚åˆ†ææˆåŠŸ")
            print(f"é¡¹ç›®åˆ†ç±»: {result['result']['project_overview']['category']}")
            return True
        else:
            print(f"âŒ éœ€æ±‚åˆ†æå¤±è´¥: {result.get('error')}")
            return False
            
    except Exception as e:
        print(f"æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹LLMé›†æˆæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•LLMæœåŠ¡
    llm_ok = await test_llm_service()
    
    # æµ‹è¯•æ™ºèƒ½ä½“
    agent_ok = await test_requirement_analysis_agent()
    
    print("\n" + "=" * 50)
    if llm_ok and agent_ok:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LLMé›†æˆæˆåŠŸ")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®")


if __name__ == "__main__":
    asyncio.run(main())